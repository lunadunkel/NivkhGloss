{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lunadunkel/NivkhGloss.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41aVcroipaE-",
        "outputId": "b52fe1b5-2300-4e0c-9998-eeeb4185b1e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NivkhGloss'...\n",
            "remote: Enumerating objects: 665, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 665 (delta 0), reused 4 (delta 0), pack-reused 658 (from 2)\u001b[K\n",
            "Receiving objects: 100% (665/665), 63.23 MiB | 15.23 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NivkhGloss.system.installation import *\n",
        "from NivkhGloss.system.models import *"
      ],
      "metadata": {
        "id": "6za2vSVqMNRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95ea3ae-f9f4-4758-9453-89c73f213209"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Установка navec...\n",
            "navec установлен\n",
            "Установка spacy...\n",
            "spacy установлен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = download_spacy_model()\n",
        "navec = download_navec()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPjX0xk0J0Xa",
        "outputId": "5b352b96-2507-48fb-d693-2e590a93cacf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Установка модели ru_core_news_sm...\n",
            "ru_core_news_sm установлен\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Загрузка Navec модели: 100%|███████████▉| 51770/51771 [00:05<00:00, 9020.64KB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('NivkhGloss/models/lemma_insert/trie.pkl', 'rb') as f:\n",
        "    trie = pickle.load(f)\n",
        "\n",
        "with open('NivkhGloss/vocabularies/glossing/stem_vocab.json') as file:\n",
        "    stem_vocab = json.load(file)"
      ],
      "metadata": {
        "id": "h9kYjtukCLnn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segm_dir = 'bpe_attention_lstm_cnn'\n",
        "\n",
        "segm_model = MorphSegmentationCNN(vocab_size=len(symb_vocab),\n",
        "    labels_number=len(label_dict), hidden_dim=512, n_layers=3, dropout=0.4,\n",
        "    device=\"cuda\", window=(3, 6), bpe_vocab_size=2500, use_attention=True,\n",
        "    use_lstm=True, use_bpe=True).to(\"cuda\")\n",
        "\n",
        "model_state_dict = torch.load('/content/NivkhGloss/models/pth/bpe_attention_lstm_cnn.pth')['model_state_dict']\n",
        "segm_model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r6bpcd1Ljjj",
        "outputId": "0ac17b9b-8d37-47ae-d023-cb957c2e734a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "postagging_dir = 'char_pos_tagging'\n",
        "\n",
        "pos_model = PosTagger(word_embedding_dim=64, char_embedding_dim=32,\n",
        "                         hidden_dim=128,  vocab_size=len(word_vocab),\n",
        "                         char_vocab_size=len(char_vocab), labels_number=len(pos_label_vocab),\n",
        "                         device=\"cuda\", use_char_ids=True, dropout=0.2).to(device=\"cuda\")\n",
        "\n",
        "\n",
        "model_state_dict = torch.load('/content/NivkhGloss/models/pth/char_pos_tagging.pth')['model_state_dict']\n",
        "pos_model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nN5jnJ0OKeg",
        "outputId": "ce0b3853-dd86-4f3d-ea5b-8e3cf72f8237"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glossing_dir = 'glossing'\n",
        "\n",
        "gloss_model = BiLSTMTagger(len(morpheme_vocab), embed_dim=128,\n",
        "                     dropout=0.5, bidirectional=False,\n",
        "                     num_layers=2, hidden_dim=256,\n",
        "                     output_dim=len(gloss_vocab), device=\"cuda\").to(\"cuda\")\n",
        "\n",
        "\n",
        "model_state_dict = torch.load('/content/NivkhGloss/models/pth/glossing.pth')['model_state_dict']\n",
        "gloss_model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ETVz41Omuvf",
        "outputId": "1d370494-9a6b-4baa-ba80-139826b63c3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NivkhGloss.system.GlossText import *"
      ],
      "metadata": {
        "id": "oaSswJGiXUjl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NivkhGlosser = GlossText(segm_model, pos_model, gloss_model,\n",
        "                         symb_vocab, char_vocab, word_vocab,\n",
        "                         pos_label_vocab, morpheme_vocab, gloss_vocab,\n",
        "                         glosses_dictionary, stem_vocab,\n",
        "                         trie, navec, nlp, device='cuda')"
      ],
      "metadata": {
        "id": "sLm1Gom9Pf7G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NivkhGlosser.gloss_sent('ӿы,\tӿарор̌\tмулкхир̌\tпыньх\tлытр̌',\n",
        "                        translation='Да. Затем в берестяной корзинке бульон рыбный варит')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HG2K1zsQLN7",
        "outputId": "cdcbc610-74ec-4706-e86d-7e3f5e580ba5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'segmentation': 'ӿы,\\tӿа-рор̌\\tмулкхир̌\\tпыньх\\tлыт-р̌',\n",
              " 'glossing': 'UNK\\tбыть.таким-CONV:ANT.3.SG\\tUNK\\tсуп\\tделать-CONV.3.SG'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_punctuation(line):\n",
        "    line = '\\t'.join(line.split())\n",
        "    new_line = re.sub('\\[[А-ЯЁ]+\\:\\]\\t', '', line)\n",
        "    new_line = re.sub('[\\.\\,\\?\\!\\:\\(\\)]+', '', new_line)\n",
        "    new_line = re.sub('^\\t|\\t$', '', new_line)\n",
        "    new_line = new_line.lower()\n",
        "    return new_line"
      ],
      "metadata": {
        "id": "FCrco6vNrLXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original = []\n",
        "translation = []\n",
        "with open('/content/n_r.txt', encoding='utf8') as file:\n",
        "    for num, line in enumerate(file):\n",
        "        line = '\\t'.join(line.strip().split())\n",
        "        if re.match('\\d+\\>\\t', line):\n",
        "            line = clear_punctuation(re.sub('\\d+\\>\\t', '', line))\n",
        "            original.append(line)\n",
        "        elif re.match('\\d+\\=\\t', line):\n",
        "            line = clear_punctuation(re.sub('\\d+\\=\\t', '', line))\n",
        "            translation.append(line)"
      ],
      "metadata": {
        "id": "Vk1sra9jrMlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glossed_text = NivkhGlosser.gloss_text(original, translation)\n",
        "f = open('a200_tmn.txt', 'w', encoding='utf8')\n",
        "f.writelines('\\n\\n'.join(glossed_text))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "sJje5-JprOCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замер качества"
      ],
      "metadata": {
        "id": "qoiPNGeNYho_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_segmentation(gold, predicted):\n",
        "    \"\"\"\n",
        "    gold: правильная сегментация(разделённых табуляцией)\n",
        "    predicted: предсказанная сегментация\n",
        "\n",
        "    Возвращает метрики: precision, recall, f1, accuracy по частям, точность по словам\n",
        "    \"\"\"\n",
        "    TP = FP = FN = 0\n",
        "    equal_parts = total_parts = 0\n",
        "    correct_words = 0\n",
        "    total_numb_words = 0\n",
        "    for gold_sent, pred_sent in zip(gold, predicted):\n",
        "        gold_list = gold_sent.split('\\t')\n",
        "        predicted_list = pred_sent.split('\\t')\n",
        "        total_numb_words += len(gold_list)\n",
        "\n",
        "        for gold, pred in zip(gold_list, predicted_list):\n",
        "            gold_parts = gold.split('-')\n",
        "            pred_parts = pred.split('-')\n",
        "\n",
        "            # print(gold_parts)\n",
        "            # print(pred_parts)\n",
        "            # Сравниваем части\n",
        "            common = [p for p in pred_parts if p in gold_parts]\n",
        "            TP += len(common)\n",
        "            FP += len(pred_parts) - len(common)\n",
        "            FN += len(gold_parts) - len(common)\n",
        "\n",
        "            # Точность по частям\n",
        "            for g, p in zip(gold_parts, pred_parts):\n",
        "                equal_parts += int(g == p)\n",
        "            total_parts += len(gold_parts)\n",
        "\n",
        "            # Полностью совпадающие слова\n",
        "            correct_words += int(gold_parts == pred_parts)\n",
        "\n",
        "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
        "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "    part_accuracy = equal_parts / total_parts if total_parts > 0 else 0\n",
        "    word_accuracy = correct_words / total_numb_words if total_numb_words > 0 else 0\n",
        "\n",
        "\n",
        "\n",
        "    metrics = [\n",
        "        (\"Точность\", precision),\n",
        "        (\"Полнота\", recall),\n",
        "        (\"F1-мера\", f1),\n",
        "        (\"Корректность по частям\", part_accuracy),\n",
        "        (\"Точность по словам\", word_accuracy)\n",
        "    ]\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "yA3M8aTfF2eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_segmented = [x['segmented'] for x in final_test]\n",
        "gold_glossing = [x['glossed'] for x in final_test]"
      ],
      "metadata": {
        "id": "e8C3WJMvSUN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for x in final_test:\n",
        "    predictions.append(NivkhGlosser.gloss_sent(x['original'], x['translation']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkePVNBqSk5m",
        "outputId": "edb5ee88-ab9f-4758-8589-7589d57630c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d30K6V4T5FP_",
        "outputId": "4f3cad22-0c1d-4227-e04d-870d46d413e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "348"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gold_glossing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QYcYAQFUkn0",
        "outputId": "0dac2b00-c351-42eb-9793-5e970a9aa41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "348"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3jATfQSNfFkX",
        "outputId": "8e9a3814-d1d8-4298-95ad-9aaa8fd63671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchtext==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchtext==0.6.0) (3.0.2)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score"
      ],
      "metadata": {
        "id": "Xya8n0BBfs3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import click\n",
        "import json\n",
        "\n",
        "\n",
        "def eval_accuracy(pred: List[List[str]], gold: List[List[str]]) -> dict:\n",
        "    \"\"\"Computes the average and overall accuracy, where predicted labels must be in the correct position in the list.\"\"\"\n",
        "    total_correct_predictions = 0\n",
        "    total_tokens = 0\n",
        "    summed_accuracies = 0\n",
        "\n",
        "    for (entry_pred, entry_gold, i) in zip(pred, gold, range(len(gold))):\n",
        "        entry_correct_predictions = 0\n",
        "\n",
        "        for token_index in range(len(entry_gold)):\n",
        "            # For each token, check if it matches\n",
        "            if token_index < len(entry_pred) and entry_pred[token_index] == entry_gold[token_index] and entry_pred[token_index] != '[UNK]':\n",
        "                entry_correct_predictions += 1\n",
        "\n",
        "        entry_accuracy = (entry_correct_predictions / len(entry_gold))\n",
        "        summed_accuracies += entry_accuracy\n",
        "\n",
        "        total_correct_predictions += entry_correct_predictions\n",
        "        total_tokens += len(entry_gold)\n",
        "\n",
        "    total_entries = len(gold)\n",
        "    average_accuracy = summed_accuracies / total_entries\n",
        "    overall_accuracy = total_correct_predictions / total_tokens\n",
        "    return {'average_accuracy': average_accuracy, 'accuracy': overall_accuracy}\n",
        "\n",
        "\n",
        "def eval_stems_grams(pred: List[List[str]], gold: List[List[str]]) -> dict:\n",
        "    perf = {'stem': {'correct': 0, 'pred': 0, 'gold': 0}, 'gram': {'correct': 0, 'pred': 0, 'gold': 0}}\n",
        "\n",
        "    for (entry_pred, entry_gold) in zip(pred, gold):\n",
        "        for token_index in range(len(entry_gold)):\n",
        "\n",
        "            # We can determine if a token is a stem or gram by checking if it is all uppercase\n",
        "            token_type = 'gram' if entry_gold[token_index].isupper() else 'stem'\n",
        "            perf[token_type]['gold'] += 1\n",
        "\n",
        "            if token_index < len(entry_pred):\n",
        "                pred_token_type = 'gram' if entry_pred[token_index].isupper() else 'stem'\n",
        "                perf[pred_token_type]['pred'] += 1\n",
        "\n",
        "                if entry_pred[token_index] == entry_gold[token_index]:\n",
        "                    # Correct prediction\n",
        "                    perf[token_type]['correct'] += 1\n",
        "\n",
        "    stem_perf = {'prec': 0 if perf['stem']['pred'] == 0 else perf['stem']['correct'] / perf['stem']['pred'],\n",
        "                 'rec': perf['stem']['correct'] / perf['stem']['gold']}\n",
        "    if (stem_perf['prec'] + stem_perf['rec']) == 0:\n",
        "        stem_perf['f1'] = 0\n",
        "    else:\n",
        "        stem_perf['f1'] = 2 * (stem_perf['prec'] * stem_perf['rec']) / (stem_perf['prec'] + stem_perf['rec'])\n",
        "\n",
        "    gram_perf = {'prec': 0 if perf['gram']['pred'] == 0 else perf['gram']['correct'] / perf['gram']['pred'],\n",
        "                 'rec': perf['gram']['correct'] / perf['gram']['gold']}\n",
        "    if (gram_perf['prec'] + gram_perf['rec']) == 0:\n",
        "        gram_perf['f1'] = 0\n",
        "    else:\n",
        "        gram_perf['f1'] = 2 * (gram_perf['prec'] * gram_perf['rec']) / (gram_perf['prec'] + gram_perf['rec'])\n",
        "    return {'stem': stem_perf, 'gram': gram_perf}\n",
        "\n",
        "\n",
        "def eval_morpheme_glosses(pred_morphemes: List[List[str]], gold_morphemes: List[List[str]]):\n",
        "    \"\"\"Evaluates the performance at the morpheme level\"\"\"\n",
        "    morpheme_eval = eval_accuracy(pred_morphemes, gold_morphemes)\n",
        "    class_eval = eval_stems_grams(pred_morphemes, gold_morphemes)\n",
        "    intersection = [len(set(x).intersection(set(y))) for x, y in zip(gold_morphemes, pred_morphemes)]\n",
        "    print(sum(intersection) / len(intersection))\n",
        "    bleu = bleu_score(pred_morphemes, [[line] for line in gold_morphemes])\n",
        "    return {'morpheme_level': morpheme_eval, 'classes': class_eval, 'bleu': bleu}\n",
        "\n",
        "\n",
        "def eval_word_glosses(pred_words: List[List[str]], gold_words: List[List[str]]):\n",
        "    \"\"\"Evaluates the performance at the morpheme level\"\"\"\n",
        "    word_eval = eval_accuracy(pred_words, gold_words)\n",
        "    bleu = bleu_score(pred_words, [[line] for line in gold_words])\n",
        "    return {'word_level': word_eval, 'bleu': bleu}\n",
        "\n",
        "\n",
        "def evaluate_igt(pred, gold):\n",
        "    \"\"\"Performs evaluation of a predicted IGT file\"\"\"\n",
        "\n",
        "    pred_words = [line.split('\\t') for line in pred]\n",
        "    gold_words = [line.split('\\t') for line in gold]\n",
        "    word_eval = eval_accuracy(pred_words, gold_words)\n",
        "\n",
        "    pred_morphemes = [re.split(\"\\t|-\", line) for line in pred]\n",
        "    gold_morphemes = [re.split(\"\\t|-\", line) for line in gold]\n",
        "\n",
        "    all_eval = {'word_level': word_eval, **eval_morpheme_glosses(pred_morphemes=pred_morphemes, gold_morphemes=gold_morphemes)}\n",
        "    print(json.dumps(all_eval, sort_keys=True, indent=4))"
      ],
      "metadata": {
        "id": "OwJzpiAaew1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_segmented = [x['segmentation'] for x in predictions]\n",
        "pred_glossing = [x['glossing'] for x in predictions]"
      ],
      "metadata": {
        "id": "lfYtfCqAYCqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def compute_chrf_morpheme_as_ngram(true_segments, predicted_segments, beta=2):\n",
        "    \"\"\"\n",
        "    Вычисляет метрику chrF++ для сегментированных данных, где морфемы рассматриваются как n-граммы.\n",
        "    \"\"\"\n",
        "    def compute_fscore(precision, recall, beta):\n",
        "        \"\"\" Вычисляет F-меру. \"\"\"\n",
        "        if precision + recall == 0:\n",
        "            return 0.0\n",
        "        return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
        "\n",
        "    ref_morphemes = Counter(true_segments)\n",
        "    hyp_morphemes = Counter(predicted_segments)\n",
        "\n",
        "    # совпадающие морфемы\n",
        "    common_morphemes = ref_morphemes & hyp_morphemes\n",
        "    matches = sum(common_morphemes.values())\n",
        "\n",
        "    # общее количество морфем\n",
        "    total_ref_morphemes = sum(ref_morphemes.values())\n",
        "    total_hyp_morphemes = sum(hyp_morphemes.values())\n",
        "\n",
        "    # точность и полнота\n",
        "    precision = matches / total_hyp_morphemes if total_hyp_morphemes > 0 else 0\n",
        "    recall = matches / total_ref_morphemes if total_ref_morphemes > 0 else 0\n",
        "\n",
        "    # вычисление F-меры\n",
        "    chrf_score = compute_fscore(precision, recall, beta)\n",
        "    return chrf_score"
      ],
      "metadata": {
        "id": "KKssTENDISHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_overall_chrf_morpheme_as_ngram(true_data, predicted_data, beta=2):\n",
        "    \"\"\"\n",
        "    Вычисляет средний chrF++ для множества сегментированных данных.\n",
        "    \"\"\"\n",
        "    scores = [\n",
        "        compute_chrf_morpheme_as_ngram(true_segments, predicted_segments, beta)\n",
        "        for true_segments, predicted_segments in zip(true_data, predicted_data)\n",
        "    ]\n",
        "    return sum(scores) / len(scores) if scores else 0.0"
      ],
      "metadata": {
        "id": "Lxgnl1EjIz58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_gold_segmented = []\n",
        "for x in gold_segmented:\n",
        "    for word in x.split('\\t'):\n",
        "        all_gold_segmented.append(word.split('-'))"
      ],
      "metadata": {
        "id": "9OFonvTPIGRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pred_segmented = []\n",
        "for x in pred_segmented:\n",
        "    for word in x.split('\\t'):\n",
        "        all_pred_segmented.append(word.split('-'))"
      ],
      "metadata": {
        "id": "59dlj4NxItlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chrf = compute_overall_chrf_morpheme_as_ngram(all_gold_segmented, all_pred_segmented)"
      ],
      "metadata": {
        "id": "Fet1qOh4I1ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chrf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-709IhskI34T",
        "outputId": "0b43a890-5024-423b-afa0-49211b4a2e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8876439587536151"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "measure_segmentation(pred_segmented, gold_segmented)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QGQXcC1GbLg",
        "outputId": "73345ddd-d62e-4e36-bd5d-838899e66128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Точность', 0.8709338929695698),\n",
              " ('Полнота', 0.8880171184022825),\n",
              " ('F1-мера', 0.8793925481193714),\n",
              " ('Корректность по частям', 0.8573466476462197),\n",
              " ('Точность по словам', 0.8619354838709677)]"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_igt(pred_glossing, gold_glossing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laH5IRgBg9va",
        "outputId": "9005dcce-d050-446e-b111-cf74644c82cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5258620689655173\n",
            "{\n",
            "    \"bleu\": 0.22517720618985276,\n",
            "    \"classes\": {\n",
            "        \"gram\": {\n",
            "            \"f1\": 0.3959357587676172,\n",
            "            \"prec\": 0.3491329479768786,\n",
            "            \"rec\": 0.45722937168811506\n",
            "        },\n",
            "        \"stem\": {\n",
            "            \"f1\": 0.30368225072403804,\n",
            "            \"prec\": 0.41704545454545455,\n",
            "            \"rec\": 0.23877683799609628\n",
            "        }\n",
            "    },\n",
            "    \"morpheme_level\": {\n",
            "        \"accuracy\": 0.3397480755773268,\n",
            "        \"average_accuracy\": 0.3601194508154002\n",
            "    },\n",
            "    \"word_level\": {\n",
            "        \"accuracy\": 0.29954809554551326,\n",
            "        \"average_accuracy\": 0.28599925776649926\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_punctuation(original, predicted):\n",
        "    pred_line = []\n",
        "    for orig, pred in zip(original.split('\\t'), predicted.split('\\t')):\n",
        "        new_pred = pred + orig[len(pred.replace('-', '')):]\n",
        "        pred_line.append(new_pred)\n",
        "    return '\\t'.join(pred_line)"
      ],
      "metadata": {
        "id": "H1f6Dnw0mtJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_file = []\n",
        "with open('23.txt', 'r') as file:\n",
        "    for num, line in enumerate(file):\n",
        "        line = line.strip()\n",
        "        number_match_segm = re.match('\\d+\\>\\t', line)\n",
        "        other = re.match('\\d+[\\<=]\\t', line)\n",
        "        # new_line = re.sub('\\[[А-ЯЁ]+\\:\\]\\t', '', line)\n",
        "\n",
        "        if number_match_segm:\n",
        "            number = re.match('\\d+', number_match_segm.group()).group()\n",
        "            speech = re.search('\\[[А-ЯЁ]+\\:\\]', line)\n",
        "\n",
        "            new_line = re.sub(number_match_segm.group(), '', line)\n",
        "            # new_pred_line = re.sub('[\\.\\,\\?\\!]+', '', new_line)\n",
        "            new_line = re.sub('\\[[А-ЯЁ]+\\:\\]\\t', '', new_line)\n",
        "            new_pred_line = re.sub('[\\.\\,\\?\\!\\:]+', '', new_line)\n",
        "\n",
        "            new_pred = glossator.gloss_sent(new_pred_line)\n",
        "            new_segm = restore_punctuation(new_line, new_pred['segmentation'])\n",
        "            if speech:\n",
        "                speech = speech.group() + '\\t'\n",
        "            else:\n",
        "                speech = ''\n",
        "            new_file.append(f'{number}>\\t{speech}{new_segm}')\n",
        "            new_gloss = new_pred['glossing']\n",
        "            new_file.append(f'{number}#\\t{speech}{new_gloss}')\n",
        "        else:\n",
        "            new_file.append(line)"
      ],
      "metadata": {
        "id": "v5XLytGXdiDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJSFgAXKMs-",
        "outputId": "03096d81-5a6e-4005-bc4c-63829f6fc1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu"
      ],
      "metadata": {
        "id": "Y7vKD7uJKQkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu.metrics import CHRF"
      ],
      "metadata": {
        "id": "1zBdZbPkKR4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_chrf(true_label, pred_label):\n",
        "    \"\"\"\n",
        "    Вычисляет метрику chrF между true_label и pred_label.\n",
        "\n",
        "    :param true_label: Истинная метка (str).\n",
        "    :param pred_label: Предсказанная метка (str).\n",
        "    :return: Значение chrF (float).\n",
        "    \"\"\"\n",
        "    chrf = CHRF()\n",
        "    score = chrf.corpus_score([pred_label], [[true_label]])\n",
        "    return score.score"
      ],
      "metadata": {
        "id": "Moo9ymyvKTpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_metric = 0\n",
        "for pred, gold in zip(gold_glossing, pred_glossing):\n",
        "\n",
        "    final_metric += compute_chrf(gold, pred)\n",
        "\n",
        "print(f'ChrF metric for segmentation: {final_metric/len(gold_glossing):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-taBvbjbKVS-",
        "outputId": "d787c950-b334-42e3-d6b2-d1d144b6b6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChrF metric for glossing: 52.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_glossing[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_LU5YlmnKaF9",
        "outputId": "de9e10c9-0bfc-4a18-d83e-e71ed931c62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'быть.таким-CONV:ANT.3.PL\\tUNK-EMPH.3.PL\\tUNK\\tесть-EMPH.3.PL\\tбыть.таким-CONV:ANT.3.PL'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_metric = 0\n",
        "for pred, gold in zip(gold_glossing, pred_glossing):\n",
        "    true_pred = re.sub('[А-яё]+(\\.[А-яё])*', 'STEM', pred)\n",
        "    true_pred = re.sub('(UNK|ADJ|PRON|DET|NOUN|VERB|ADV)+', 'STEM', true_pred)\n",
        "    true_gold = re.sub('(UNK|ADJ|PRON|DET|NOUN|VERB|ADV)+', 'STEM', gold)\n",
        "    true_gold = re.sub('[А-яё]+(\\.[А-яё])*', 'STEM', true_gold)\n",
        "    final_metric += compute_chrf(true_gold, true_pred)\n",
        "\n",
        "print(f'ChrF metric for glossing (only grammatical morphs): {final_metric/len(gold_glossing):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqo8YOWYKvxB",
        "outputId": "17add232-e136-4a77-8118-1e0f2fe542b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChrF metric for glossing (only grammatical morphs): 80.48\n"
          ]
        }
      ]
    }
  ]
}